summary(interceptOnly)
anova(interceptOnly)
anova(interceptOnly)[2]
anova(interceptAndSlope)[2] / anova(interceptOnly)[2]
anova(interceptAndSlope)[[2]] / anova(interceptOnly)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)
anova(interceptAndSlope)[[2, 1]]
anova(interceptAndSlope)[[1, 2]]
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)
anova(interceptOnly)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
library(ggplot2)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
View(dat)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
mns
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, sd(runif(40)))
hist(mns)
data(sleep)
sleep <- sleep
View(sleep)
1100 + c(-1, 1) * qt(0.975, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30 / (9)^.4
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30 / (9)^.5
help qt
?qt
xbar <- 1100
sd <- 30
n <- 9
mean + c(-1, 1) * qt(0.95, n-1) * (sd / sqrt(n))
xbar <- 1100
sd <- 30
n <- 9
xbar + c(-1, 1) * qt(0.95, n-1) * (sd / sqrt(n))
xbar <- 1100
sd <- 30
n <- 9
xbar + c(-1, 1) * qt(0.975, n-1) * (sd / sqrt(n))
qt(0.975, 8)
xbar <- -2
n <- 9
xbar * sqrt(n) / qt(0.975, n-1)
xbar_old <- 3
sd_old <- 0.6
n_old <- 10
xbar_new <- 5
sd_new <- 0.68
n_new <- 10
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 3
sd_old <- 0.6
n_old <- 10
xbar_new <- 5
sd_new <- 0.68
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
sd_old <- 0.68
n_old <- 10
xbar_new <- 3
sd_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(n_new - n_old) + c(-1, 1) * qt(0.975 / 2, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
sd_old <- 0.68
n_old <- 10
xbar_new <- 3
sd_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old) + ((n_new - 1)*sd_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) / sqrt((n_old) + (n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(xbar_new - xbar_old) + c(-1, 1) * qt(0.95, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 6
var_old <- 2
n_old <- 100
xbar_new <- 4
var_new <- 0.5
n_new <- 100
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 6
var_old <- 2
n_old <- 100
xbar_new <- 4
var_new <- 0.5
n_new <- 100
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_old - xbar_new) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_placebo - xbar_treatment) + c(-1, 1) * qt(0.975, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_placebo - xbar_treatment) + c(-1, 1) * qt(0.95, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_treatment - xbar_placebo) + c(-1, 1) * qt(0.95, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
?power.t.test
week1 <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
t.test(week1, week2, alternative = "two.sided", paired = T)
week1 <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
t.test(week1, week2, alternative = "two.sided", paired = T)
m0 <- 1081
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1119
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1031
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1080
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1077
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
n = 9; mu = 1100; sd=30
mu + c(-1,1) * qt(.975, n-1) * sd/sqrt(n)
n <- 9
m0 <- 1100
sd <- 30
m0 + c(-1, 1) * qt(.975, n - 1) * sd / sqrt(n)
binom.test(3, 4, alt= "greater")$p.value
?poisson.test
poisson.test(x = 10, T = 1787, r = 1/100, alternative = "less")$p.value
poisson.test(x = 10, T = 1787, r = 1/100, alternative = "less")
n <- 100 #subject
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- power.t.test(n=n, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$power
round(pow, 2)
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- 0.9 #power
n <- power.t.test(power=pow, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$n
ceiling(n/10)*10
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
names(shuttle)
?glm
fit <- glm(use ~ wind, family='binomial', shuttle)
exp(fit$coeff)
fit <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
exp(fit$coeff)
library(MASS)
head(shuttle)
shuttle2<-shuttle
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
#shuttle2$wind2<-as.numeric(shuttle2$wind=='head')
#head(shuttle2)
fit<-glm(use2 ~ factor(wind) - 1, family = binomial, data = shuttle2)
#0.03181
#fit<-glm(use ~ wind, family = binomial, data = shuttle)
#anova(fit)
summary(fit)$coef
fit<-glm(use2 ~ factor(wind) + factor(magn) - 1, family = binomial, data = shuttle2)
summary(fit)$coef
exp(coef(fit))
exp(cbind(OddsRatio = coef(fit), confint(fit)))
1.286 / 1.327
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data <- AlzheimerDisease
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
# Set working directory
setwd("~/Documents/GitHub/coursera-datascience-practical-machine-learning-project")
# Load relevant libraries
library(caret)
library(rattle)
# Load in training and test datasets
train <- read.csv("pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
test <- read.csv("pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
# Checking dimension of training and testing data
dim(train)
dim(test)
# Delete columns with all missing values
train <- train[ , colSums(is.na(train)) == 0]
test <- test[ , colSums(is.na(test)) == 0]
# Drop variables that are not useful to the machine learning
train <- train[ , -c(1:7)]
test <- test[ , -c(1:7)]
# Segmenting training dataset for cross validation purposes using a 60:40 split
ss <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTraining <- train[ss, ]
subTesting <- train[-ss, ]
# Predicting with trees
modFitTree <- train(classe ~ ., method = "rpart", data = subTraining)
# Looking at the tree predicted
print(modFitTree$finalModel)
# Plotting the plot tree
plot(modFitTree$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFitTree$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFitTree$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFitTree$finalModel)
set.seed(100)
modFitTree <- train(classe ~ ., method = "rpart", data = subTraining)
predict(modFit, newdata = subTesting)
predict(modFitTree, newdata = subTesting)
prediction <- predict(modFitTree, newdata = subTesting)
testing <- data.frame(prediction, subTesting$classe)
View(testing)
View(testing)
confusionMatrix(prediction, subTesting$classe)
set.seed(100)
modFitTree <- train(classe ~ ., method = "rpart", data = subTraining)
fancyRpartPlot(modFitTree$finalModel)
prediction <- predict(modFitTree, newdata = subTesting)
confusionMatrix(prediction, subTesting$classe)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
library(rpart)
modFitA1 <- rpart(classe ~ ., data=subTraining, method="class")
fancyRpartPlot(modFitA1$finalModel)
library(rattle)
fancyRpartPlot(modFitA1$finalModel)
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, subTesting, type = "class")
confusionMatrix(predictionsA1, subTesting$classe)
library(caret)
confusionMatrix(predictionsA1, subTesting$classe)
?rpart
?train
# Set working directory
setwd("~/Documents/GitHub/coursera-datascience-practical-machine-learning-project")
# Load relevant libraries
library(caret)
library(rattle)
# Load in training and test datasets
train <- read.csv("pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
test <- read.csv("pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
# Checking dimension of training and testing data
dim(train)
dim(test)
# Delete columns with all missing values
train <- train[ , colSums(is.na(train)) == 0]
test <- test[ , colSums(is.na(test)) == 0]
# Drop variables that are not useful to the machine learning
train <- train[ , -c(1:7)]
test <- test[ , -c(1:7)]
# Segmenting training dataset for cross validation purposes using a 60:40 split
ss <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTraining <- train[ss, ]
subTesting <- train[-ss, ]
# Predicting with trees
set.seed(100)
modFitTree <- train(classe ~ ., method = "rpart", data = subTraining)
# Looking at the tree predicted
print(modFitTree$finalModel)
# Plotting the plot tree
fancyRpartPlot(modFitTree$finalModel)
# Generating predictions
prediction_modFitTree <- predict(modFitTree, newdata = subTesting)
confusionMatrix(prediction_modFitTree, subTesting$classe)
set.seed(100)
modFitTree <- train(classe ~ ., method = "rpart", data = subTraining)
fancyRpartPlot(modFitTree$finalModel)
prediction_modFitTree <- predict(modFitTree, newdata = subTesting)
confusionMatrix(prediction_modFitTree, subTesting$classe)
?train
modFitTree2 <- train(classe ~ ., method = "logicBag", data = subTraining)
modFitTree2 <- train(classe ~ ., method = "LogitBoost", data = subTraining)
modFitTree2 <- train(classe ~ ., method = "LogitBoost", data = subTraining)
modFitTree2 <- train(classe ~ ., method = "treeBag", data = subTraining)
modFitTree2 <- train(classe ~ ., method = "treebag", data = subTraining)
